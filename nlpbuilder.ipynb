{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:46.666505500Z",
     "start_time": "2023-11-17T00:47:46.129153100Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing all required libraries\n",
    "\n",
    "import os\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First Two Sections: NAME + CONTACT and EDUCATION\n",
    "#I need to structure this so that, when I export it as a docx, it can be ATS friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:48.507889400Z",
     "start_time": "2023-11-17T00:47:48.502288300Z"
    }
   },
   "outputs": [],
   "source": [
    "def section1(resume_text):\n",
    "    #Print Name and Contact Information\n",
    "    name = \"Rosa Kim Cho\"\n",
    "    contact_info = \"(909) 973-7826 | rkimcho343@gmail.com | www.linkedin.com/in/rkc317/ | https://chobotis.github.io \"\n",
    "    return name, contact_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:49.934130200Z",
     "start_time": "2023-11-17T00:47:49.927132500Z"
    }
   },
   "outputs": [],
   "source": [
    "#Print Education\n",
    "def section2(resume_text):\n",
    "    #Print Education both Masters and Bachelors\n",
    "    masters = \"Computer Science, Master of Science, California State University, Fullerton, 9/2018 - 5/2023\"\n",
    "    bachelors = \"Cognitive Science, Bachelor of Science, University of California, San Diego, 9/2009 - 9/2014\"\n",
    "    return masters, bachelors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3rd Section: Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:51.590446600Z",
     "start_time": "2023-11-17T00:47:51.585914300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def section3(resume_text):\n",
    "    # Load the keyword dict\n",
    "    keyword_dict = ['Statistics', 'statistical models','statistical modeling','probability','normal distribution','poisson distribution','hypothesis testing','regression analysis','survival models','bayesian inference','factor analysis','forecasting','markov chain','monte carlo','Machine Learning','linear regression','logistic regression','k means','random forest','xgboost','svm','naive bayes','pca','decision trees','svd','ensemble models','boltzman machine','artificial intelligence','model evaluation','validation','performance tuning','infrastructure','frameworks','preprocessing','feature engineering',\n",
    "    'Deep Learning','neural network', 'keras', 'theanos','face detection','neural networks','convolutional neural network','cnn', 'recurrent neural network','rnn','object detection','computer vision','yolo','gpu','cuda','tensorflow','lstm','gan','opencv','data scientist','Pytorch','R Language','r','ggplot','shiny','cran','dplyr','tidyr','lubridate','knitr','python','flask','django','pandas','numpy','scikitlearn','sklearn','matplotlib','scipy','bokeh','statsmodel','NLP','natural language processing','topic modeling','lda','named entity recognition','pos tagging','word2vec','word embedding','lsi','spacy','gensim','nltk','nmf','doc2vec','cbow','bag of words','skip gram','bert','sentiment analysis','chat bot','Data Engineering','aws','ec2','amazon redshift','s3','docker','kubernetes','scala','teradata','google big query','aws lambda','aws emr','hive','hadoop','sql','azure','data engineer','Spark','Programming','JAVA','C++','C#','algorithm','pipeline']\n",
    "    \n",
    "    # Read the job description from a text file\n",
    "    with open('C:/Users/rkimc/Documents/nlpbuilder/job_desc.txt', 'r') as file:\n",
    "        text = file.read().replace(\"\\\\n\", \"\").lower()\n",
    "    \n",
    "    # Tokenize the text using NLTK and filter stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_text = [word for word in word_tokenize(text) if word.lower() not in stop_words and word.isalnum()]\n",
    "    \n",
    "    # Train a simple Word2Vec model\n",
    "    model = Word2Vec([tokenized_text], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    \n",
    "    # Extract keywords using Gensim Word2Vec model\n",
    "    keywords = set(model.wv.index_to_key)\n",
    "    \n",
    "    # Match keywords in the text\n",
    "    matched_keywords = set(word for word in tokenized_text if word in keyword_dict or word in keywords)\n",
    "    \n",
    "    # Print the set of matched keywords (unique instances)\n",
    "    #print(matched_keywords)\n",
    "    \n",
    "    return matched_keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4th section: Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:53.159944800Z",
     "start_time": "2023-11-17T00:47:53.153947Z"
    }
   },
   "outputs": [],
   "source": [
    "def section4(job_keywords):\n",
    "\n",
    "    #This is where the Experience Library is \n",
    "    \n",
    "        #summon Experience Library \n",
    "    experience_dict = [\n",
    "        {\n",
    "            'Title': 'Open Source Programmer',\n",
    "            'Employment Type': 'Freelance',\n",
    "            'Dates': 'April 2014 - Present',\n",
    "            'Responsibilities': [\n",
    "                'Worked on open source projects, Blender and Krita',\n",
    "                'For Blender, I improved add-ons that were used to create various 3D shapes from a torus (donut) to a square pyramid',\n",
    "                'For Krita, I aided in UI redesigns to help improve user performance and input'\n",
    "            ]\n",
    "        },\n",
    "               {\n",
    "            'Title': 'Computer Vision Researcher',\n",
    "            'Employment Type': 'Student',\n",
    "            'Dates': 'September 2022 - May 2023',\n",
    "            'Responsibilities': [\n",
    "                'Researched neural networks and medical imaging for my master’s final project which was about creating a neural network that detected and classified brain tumors in MRI scans',\n",
    "                '\tUtilizing 5 different deep learning models, each model’s purpose was to detect and categorize the tumors into these categories: glioblastoma, glioma, meningioma, or no tumors present',\n",
    "                '\tProject returned an 80%-98% accuracy rate based off of over 2000 images taken from the Cancer Imaging Archives'\n",
    "            ]\n",
    "        },\n",
    "               {\n",
    "            'Title': 'Tutor ',\n",
    "            'Employment Type': 'Freelance',\n",
    "            'Dates': 'September 2022 - May 2023',\n",
    "            'Responsibilities': [\n",
    "                'Taught Python programming for students whose skill sets ranged from absolute beginners to intermediate-leveled programmers',\n",
    "                'Built a portfolio for an aspiring game developer specializing in Unreal Engine, C++ Programming, and OpenGL',\n",
    "                '\tEducated students on how to program in Assembly (x86) language in order to pass the course, CPSC 240: Assembly'\n",
    "            ]\n",
    "        },\n",
    "               {\n",
    "            'Title': 'Data Analyst',\n",
    "            'Employment Type': 'Freelance',\n",
    "            'Dates': 'May 2023 - Present',\n",
    "            'Responsibilities': [\n",
    "                'Created data visualizations using Tableau and Power BI based off of thousands of bytes of data',\n",
    "                'Projects ranged from private accounting to predictive analysis of tiktok trends',\n",
    "                'Presentations based off of my data visualizations and analyses led to a 10-25% improvement in productivity'\n",
    "            ]\n",
    "        },\n",
    "               {\n",
    "            'Title': 'Machine Learning Programmer',\n",
    "            'Employment Type': 'Student',\n",
    "            'Dates': 'February 2022 - May 2022',\n",
    "            'Responsibilities': [\n",
    "                'Worked on the Image Repair and Restoration Machine Learning project was published and presented at the AIST 2022 Conference which was dedicated to the field of Artificial Intelligence and my paper was nominated for the Best Presentatio',\n",
    "                'It debuted during the Computer Images Panel and was a part of the series dedicated to showcasing the diversity of research featured in the fields of computer graphics, image processing, and computer vision',\n",
    "                'The publication can be read at this link: https://ieeexplore.ieee.org/document/10065203'\n",
    "            ]\n",
    "        },\n",
    "               {\n",
    "            'Title': 'NLP Analyst',\n",
    "            'Employment Type': 'Freelance',\n",
    "            'Dates': 'June 2023 - Present',\n",
    "            'Responsibilities': [\n",
    "                'Created an NLP-learning machine that takes in a collection of every single resume I’ve created and turns them into a presentable, professional draft customized per user and their interests',\n",
    "                'While the resume builder does not return a 100% perfectly well-written resume, it still follows the criteria of being able to create a template that is divided into four distinct sections (Name  & Contact, Education, Skills, Experience) ',\n",
    "                '•\tThe NLP machine was built using Pandas, nltk, gensim, and other deep learning libraries commonly implemented in these projects.'\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    \n",
    "     # Function to count matched keywords\n",
    "    matched_keywords = section3(resume_text)\n",
    "    \n",
    "    # Find all matches (in case of ties)\n",
    "    all_matches = []\n",
    "    \n",
    "    for job_entry in experience_dict:\n",
    "        responsibilities = job_entry.get('Responsibilities', [])\n",
    "        count_matches = sum(keyword.lower() in responsibility.lower() for keyword in matched_keywords for responsibility in responsibilities)\n",
    "        \n",
    "        if count_matches > 0:\n",
    "            # Add the job entry along with the count of matches\n",
    "            all_matches.append({'job_entry': job_entry, 'count_matches': count_matches})\n",
    "\n",
    "    # Sort the matches based on the count of matches in descending order\n",
    "    all_matches = sorted(all_matches, key=lambda x: x['count_matches'], reverse=True)\n",
    "\n",
    "    return all_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Connect the dots \n",
    "#Ex. If job description states \"Data Analyst\" AND contains keywords \"tableau\", insert Data Analyst and Data Visualizer and Student Researcher into Experience section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:47:54.713482800Z",
     "start_time": "2023-11-17T00:47:54.631791Z"
    }
   },
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def build_resume(resume_text, job_description_path):\n",
    "    # Extract information from the resume\n",
    "    name, contact_info = section1(resume_text)\n",
    "    education_info = section2(resume_text)\n",
    "    job_keywords = section3(job_description_path)\n",
    "    experience_section = section4(job_keywords)\n",
    "\n",
    "    # Create a new Word document\n",
    "    document = Document()\n",
    "\n",
    "    # Add sections to the document\n",
    "    document.add_heading('1. Name + Contact Information:', level=1)\n",
    "    document.add_paragraph(f\"   Name: {name}\")\n",
    "    document.add_paragraph(f\"   Contact: {contact_info}\\n\")\n",
    "\n",
    "    document.add_heading('2. Education:', level=1)\n",
    "    document.add_paragraph(f\"   {education_info}\\n\")\n",
    "\n",
    "    document.add_heading('3. Skills:', level=1)\n",
    "    document.add_paragraph(f\"   Keywords: {', '.join(job_keywords)}\\n\")\n",
    "\n",
    "    document.add_heading('4. Experience:', level=1)\n",
    "    for entry in experience_section:\n",
    "        job_entry = entry['job_entry']\n",
    "        count_matches = entry['count_matches']\n",
    "\n",
    "        document.add_heading(f\"{job_entry['Title']} ({count_matches} keyword matches)\", level=2)\n",
    "        document.add_paragraph(f\"   Employment Type: {job_entry['Employment Type']}\")\n",
    "        document.add_paragraph(f\"   Dates: {job_entry['Dates']}\")\n",
    "        document.add_paragraph(f\"   Responsibilities:\")\n",
    "        for responsibility in job_entry['Responsibilities']:\n",
    "            document.add_paragraph(f\"      - {responsibility}\")\n",
    "\n",
    "        document.add_paragraph('\\n')  # Add a blank line between entries\n",
    "\n",
    "    # Save the Word document\n",
    "    document.save('resume.docx')\n",
    "\n",
    "# Example usage\n",
    "resume_text = \"Resume: \"\n",
    "job_description_path = \"C:/Users/rkimc/Documents/nlpbuilder/job_desc.txt\"\n",
    "build_resume(resume_text, job_description_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
